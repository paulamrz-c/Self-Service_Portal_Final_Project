{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39cf2c2",
   "metadata": {},
   "source": [
    "# **Deep Learning Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076238cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from embedding_hf import encode_texts\n",
    "from models import Classifier\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e3fb6",
   "metadata": {},
   "source": [
    "## **Load CSV and generate embeddings**\n",
    " Convert phrases in embeddings using same hugging face.\n",
    "\n",
    "Input text list  ([\"How do I pay?\", \"I’m stressed\", ...])\n",
    "\n",
    "Output: Matrix NumPy with vectors of 384 dim (X.shape = (60, 384)) --> 60 phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8410c543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load trainning queryes\n",
    "df = pd.read_csv(\"../data/raw/training_queries.csv\")\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "# Transform into embeddings\n",
    "X = encode_texts(texts)  # numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e455a49",
   "metadata": {},
   "source": [
    "## **Encode labels**\n",
    "\n",
    "Using LabelEncoder to convert text to number, then to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3546df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(labels)  # convert to [0, 1, 2]\n",
    "y = torch.tensor(y_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adfc6b7",
   "metadata": {},
   "source": [
    "## **Create Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcf10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "class QueryDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = QueryDataset(X_train, y_train)\n",
    "val_dataset = QueryDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380db120",
   "metadata": {},
   "source": [
    "## **Defining MLP model**\n",
    "\n",
    "1. Input Layer 384 dim (Dense (Linear))\n",
    "2. Relu (activation function)\n",
    "2. Dropout avoid overfitting - Regularization\n",
    "3. Lineal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cb1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, input_dim=384, hidden_dim=128, output_dim=3):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         return self.fc2(x)\n",
    "\n",
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdc3d0",
   "metadata": {},
   "source": [
    "## **Training & Saving the model**\n",
    "\n",
    "we setup early stopper to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d312a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 13.7284 | Val Loss: 4.0584 | Accuracy: 63.16%\n",
      "Epoch 2/20 - Train Loss: 13.0515 | Val Loss: 3.9067 | Accuracy: 78.95%\n",
      "Epoch 3/20 - Train Loss: 12.2884 | Val Loss: 3.6808 | Accuracy: 89.47%\n",
      "Epoch 4/20 - Train Loss: 11.2064 | Val Loss: 3.3885 | Accuracy: 89.47%\n",
      "Epoch 5/20 - Train Loss: 9.7377 | Val Loss: 3.0572 | Accuracy: 94.74%\n",
      "Epoch 6/20 - Train Loss: 8.2233 | Val Loss: 2.7126 | Accuracy: 94.74%\n",
      "Epoch 7/20 - Train Loss: 6.9473 | Val Loss: 2.3870 | Accuracy: 100.00%\n",
      "Epoch 8/20 - Train Loss: 5.9228 | Val Loss: 2.0577 | Accuracy: 100.00%\n",
      "Epoch 9/20 - Train Loss: 4.6073 | Val Loss: 1.7772 | Accuracy: 100.00%\n",
      "Epoch 10/20 - Train Loss: 3.7979 | Val Loss: 1.5457 | Accuracy: 100.00%\n",
      "Epoch 11/20 - Train Loss: 3.0570 | Val Loss: 1.3518 | Accuracy: 100.00%\n",
      "Epoch 12/20 - Train Loss: 2.5391 | Val Loss: 1.1801 | Accuracy: 100.00%\n",
      "Epoch 13/20 - Train Loss: 2.0307 | Val Loss: 1.0337 | Accuracy: 100.00%\n",
      "Epoch 14/20 - Train Loss: 1.7842 | Val Loss: 0.9202 | Accuracy: 100.00%\n",
      "Epoch 15/20 - Train Loss: 1.5578 | Val Loss: 0.8285 | Accuracy: 100.00%\n",
      "Epoch 16/20 - Train Loss: 1.3290 | Val Loss: 0.7536 | Accuracy: 100.00%\n",
      "Epoch 17/20 - Train Loss: 1.2517 | Val Loss: 0.6785 | Accuracy: 100.00%\n",
      "Epoch 18/20 - Train Loss: 0.9649 | Val Loss: 0.6149 | Accuracy: 100.00%\n",
      "Epoch 19/20 - Train Loss: 0.8615 | Val Loss: 0.5685 | Accuracy: 100.00%\n",
      "Epoch 20/20 - Train Loss: 0.7064 | Val Loss: 0.5203 | Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 20\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 3  # before to stop if does not improve\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss:.4f} | Val Loss: {val_loss:.4f} | Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    # EARLY STOPPING\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"../models/best_query_classifier.pt\")  # Saving the best model\n",
    "        # torch.save(model, \"../models/best_query_classifierFULL.pt\")\n",
    "\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"⏹️ Early stopping at epoch {epoch+1}. Best val loss: {best_val_loss:.4f}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b86804",
   "metadata": {},
   "source": [
    "## **Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa557d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Encode\n"
     ]
    }
   ],
   "source": [
    "with open(\"../models/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Saving Encode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb61349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I make a payment? → faq\n",
      "Where can I access VMock? → faq\n",
      "Nothing is working and I'm tired. → offramp\n",
      "I need help with OSAP documents. → resource\n",
      "Can someone please help me? I'm so confused. → offramp\n",
      "Hola → chitchat\n",
      "hi again → chitchat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "c:\\Users\\paula\\github-classroom\\Self-Service_Portal_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def classify_query(text):\n",
    "    embedding = encode_texts([text])  # np array con shape (1, 384)\n",
    "    tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    return le.inverse_transform([pred])[0]\n",
    "\n",
    "examples = [\n",
    "    \"How do I make a payment?\",\n",
    "    \"Where can I access VMock?\",\n",
    "    \"Nothing is working and I'm tired.\",\n",
    "    \"I need help with OSAP documents.\",\n",
    "    \"Can someone please help me? I'm so confused.\",\n",
    "    \"Hola\",\n",
    "    \"hi again\"\n",
    "]\n",
    "\n",
    "for text in examples:\n",
    "    print(f\"{text} → {classify_query(text)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
