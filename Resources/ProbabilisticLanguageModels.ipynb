{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c8efae",
   "metadata": {},
   "source": [
    "# Lab 7 - IR IRBasics Vector Space Proximity Workshop\n",
    "\n",
    "`Group 7:`\n",
    "- Paula Ramirez 8963215\n",
    "- Hasyashri Bhatt 9028501\n",
    "- Babandeep 9001552"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e160c9d",
   "metadata": {},
   "source": [
    "## üìÑ Step 1: Document Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc964464",
   "metadata": {},
   "source": [
    "We collect a set of text documents to build our inverted index. The documents are from Free eBooks | Project Gutenberg (https://www.gutenberg.org/),which include various topics like crime, history, and more.\n",
    "\n",
    "### üîß Our documents:\n",
    "- we collected 20 text documents into the `sample_docs folder`, from above source. \n",
    "- All has plain text and more than 2000 words.\n",
    "- Load the documents into a list for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ee0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents.\n"
     ]
    }
   ],
   "source": [
    "# Example: Load text files from a folder\n",
    "import os\n",
    "\n",
    "def load_documents(folder_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                documents.append(file.read())\n",
    "    return documents\n",
    "\n",
    "# Replace 'sample_docs/' with your actual folder\n",
    "documents = load_documents('sample_docs/')\n",
    "print(f\"Loaded {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f0cb2",
   "metadata": {},
   "source": [
    "This function read all documents from the `sample_docs` folder and returns the number documents loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342945a",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Step 2: Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803fb52",
   "metadata": {},
   "source": [
    "In this section we created a basic tokenizer to process the text documents. This tokenizer split each document into tokens (words) and removes punctuation. It also converts all tokens to lowercase and with a regular expression to remove any non-alphanumeric characters.\n",
    "\n",
    "At the end of this block, we will have a list of tokens for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4806fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'glimpses', 'of', 'the', 'dark', 'ages', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return tokens\n",
    "\n",
    "# Test on one document\n",
    "tokens = tokenize(documents[0])\n",
    "print(tokens[:20])  # Preview first 20 tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed76ec",
   "metadata": {},
   "source": [
    "## üîÅ Step 3: Normalization Pipeline (Stemming, Stop Word Removal, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f277a0d",
   "metadata": {},
   "source": [
    "Using `nltk` library, we will implement a normalization pipeline that includes stemming and stop word removal. This will help us reduce the vocabulary size and focus on the most relevant terms in our documents.\n",
    "\n",
    "For example, the word \"anyone\" will be stemmed to \"anyon\", and \"glimpse\" will be stemmed to \"glimps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ae9a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'glimps', 'dark', 'age', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords', quiet=True)  # Suppress download warnings\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def normalize_tokens(tokens):\n",
    "    return [stemmer.stem(t) for t in tokens if t not in stop_words]\n",
    "\n",
    "# Example: normalize one document\n",
    "norm_tokens = normalize_tokens(tokens)\n",
    "print(norm_tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ac4a5",
   "metadata": {},
   "source": [
    "## Previous token:\n",
    "\n",
    "`['the', 'project', 'gutenberg', 'ebook', 'of', 'glimpses', 'of', 'the', 'dark', 'ages', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in']`\n",
    "\n",
    "## After remove stopwords and applying stemming:\n",
    "\n",
    "`['project', 'gutenberg', 'ebook', 'glimps', 'dark', 'age', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev', 'may', 'copi']`\n",
    "\n",
    "The difference between the previous and the new token is that the previous token contains stopwords such as \"the\", \"of\", \"is\", \"for\", \"in\", etc., while the new token has these words removed, leaving only the significant words that contribute to the meaning of the text.\n",
    "We saw that some letters were removed from the words, this is because we applied stemming to the words, which reduces them to their root form. For example, \"glimpses\" becomes \"glimps\", \"ages\" becomes \"age\", and \"anyone\" becomes \"anyon\". This helps in reducing the vocabulary size and improving search accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34cf58",
   "metadata": {},
   "source": [
    "## üîç Step 4: Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c39dd",
   "metadata": {},
   "source": [
    "In this step, we are creating an inverted index from the processed tokens. The inverted index maps each unique token to the list of documents (or their IDs) where that token appears. This is a crucial step in building an efficient search engine.\n",
    "\n",
    "One example is: \n",
    "\n",
    "`'glimps': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca8f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term\t\tDoc IDs\n",
      "project\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "gutenberg\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "ebook\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "glimps\t\t[0, 3, 6, 7, 8, 10, 12, 14, 15]\n",
      "dark\t\t[0, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16]\n",
      "age\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "use\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "anyon\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "anywher\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "unit\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "state\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "part\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "world\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "cost\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "almost\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "restrict\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "whatsoev\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "may\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "copi\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "give\t\t[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_inverted_index(documents):\n",
    "    index = defaultdict(list)\n",
    "    for doc_id, text in enumerate(documents):\n",
    "        tokens = normalize_tokens(tokenize(text))\n",
    "        seen = set()\n",
    "        for token in tokens:\n",
    "            if token not in seen:\n",
    "                index[token].append(doc_id)\n",
    "                seen.add(token)\n",
    "    return index\n",
    "\n",
    "inverted_index = build_inverted_index(documents)\n",
    "\n",
    "# print first 20 terms in the inverted index in a table format\n",
    "print(\"Term\\t\\tDoc IDs\")\n",
    "for term, doc_ids in list(inverted_index.items())[:20]:\n",
    "    print(f\"{term}\\t\\t{doc_ids}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef4df8",
   "metadata": {},
   "source": [
    "## üß™ Test: Phrase Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db832216",
   "metadata": {},
   "source": [
    "Here, we are implementing queries using positional indexing. This allows us to search for phrases within the documents.\n",
    "\n",
    "To support **exact phrase search**, we store the position of each word in each document. The search function only returns documents where the full sequence of words appears **in order and without gaps**.\n",
    " \n",
    "We test two phrases:\n",
    "- `\"crime and punishment\"`\n",
    "- `\"this ebook\"`\n",
    " \n",
    "The function will print document indices and a short preview from each result for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c60c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Results for 'crime and punishment': [3, 16]\n",
      "‚Üí Doc 3 preview: ÔªøThe Project Gutenberg eBook of Crime and Punishment\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of th...\n",
      "‚Üí Doc 16 preview: ÔªøThe Project Gutenberg eBook of Voyage to the East Indies\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts ...\n",
      "üîé Results for 'this ebook': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "‚Üí Doc 0 preview: ÔªøThe Project Gutenberg eBook of Glimpses of the Dark Ages\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts ...\n",
      "‚Üí Doc 1 preview: ÔªøThe Project Gutenberg eBook of Hannele\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no...\n",
      "‚Üí Doc 2 preview: ÔªøThe Project Gutenberg eBook of A history of the Peninsular War, Vol. 3, Sep. 1809-Dec. 1810\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the ...\n",
      "‚Üí Doc 3 preview: ÔªøThe Project Gutenberg eBook of Crime and Punishment\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of th...\n",
      "‚Üí Doc 4 preview: ÔªøThe Project Gutenberg eBook of The Eyes Have It\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the wo...\n",
      "‚Üí Doc 5 preview: ÔªøThe Project Gutenberg eBook of A Doll's House : a play\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of...\n",
      "‚Üí Doc 6 preview: ÔªøThe Project Gutenberg eBook of Hamlet, Prince of Denmark\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts ...\n",
      "‚Üí Doc 7 preview: ÔªøThe Project Gutenberg eBook of Moby Dick; Or, The Whale\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts o...\n",
      "‚Üí Doc 8 preview: ÔªøThe Project Gutenberg eBook of Cambridge Sketches\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the ...\n",
      "‚Üí Doc 9 preview: ÔªøThe Project Gutenberg eBook of The Sceptical Chymist\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of t...\n",
      "‚Üí Doc 10 preview: ÔªøThe Project Gutenberg eBook of Right Ho, Jeeves\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the wo...\n",
      "‚Üí Doc 11 preview: ÔªøThe Project Gutenberg eBook of √âcrits spirituels de Charles de Foucauld\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "mo...\n",
      "‚Üí Doc 12 preview: ÔªøThe Project Gutenberg eBook of Dracula\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no...\n",
      "‚Üí Doc 13 preview: ÔªøThe Project Gutenberg eBook of The dialogues of Plato in five volumes, Vol. II (of 5)\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United...\n",
      "‚Üí Doc 14 preview: ÔªøThe Project Gutenberg eBook of Bog-trotting for orchids\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts o...\n",
      "‚Üí Doc 15 preview: ÔªøThe Project Gutenberg eBook of The adventures of Heine\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of...\n",
      "‚Üí Doc 16 preview: ÔªøThe Project Gutenberg eBook of Voyage to the East Indies\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts ...\n",
      "‚Üí Doc 17 preview: ÔªøThe Project Gutenberg eBook of The art of fiction\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the ...\n",
      "‚Üí Doc 18 preview: ÔªøThe Project Gutenberg eBook of Or√≠genes de la novela - Vol. III\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other...\n",
      "‚Üí Doc 19 preview: ÔªøThe Project Gutenberg eBook of Juomalakko\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at...\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# --- Positional Index for Phrase Queries ---\n",
    "def build_positional_index(documents):\n",
    "    positional_index = defaultdict(lambda: defaultdict(list))\n",
    "    for doc_id, text in enumerate(documents):\n",
    "        tokens = normalize_tokens(tokenize(text))\n",
    "        for pos, token in enumerate(tokens):\n",
    "            positional_index[token][doc_id].append(pos)\n",
    "    return positional_index\n",
    "\n",
    "# --- Phrase Query Search Function ---\n",
    "def phrase_search(query, positional_index):\n",
    "    words = normalize_tokens(tokenize(query))\n",
    "    if not words:\n",
    "        return []\n",
    "    doc_sets = [set(positional_index[word].keys()) for word in words if word in positional_index]\n",
    "    if len(doc_sets) != len(words):\n",
    "        return []\n",
    "    candidate_docs = set.intersection(*doc_sets)\n",
    "    matching_docs = []\n",
    "    for doc_id in candidate_docs:\n",
    "        positions = [positional_index[word][doc_id] for word in words]\n",
    "        for pos in positions[0]:\n",
    "            if all((pos + i) in positions[i] for i in range(1, len(words))):\n",
    "                matching_docs.append(doc_id)\n",
    "                break\n",
    "    return matching_docs\n",
    "\n",
    "# --- Build Positional Index ---\n",
    "positional_index = build_positional_index(documents)\n",
    "\n",
    "# --- Test Phrase Queries ---\n",
    "query1 = \"crime and punishment\"\n",
    "query2 = \"this ebook\"\n",
    "\n",
    "results1 = phrase_search(query1, positional_index)\n",
    "results2 = phrase_search(query2, positional_index)\n",
    "\n",
    "print(f\"üîé Results for '{query1}':\", results1)\n",
    "for i in results1:\n",
    "    print(f'‚Üí Doc {i} preview: {documents[i][:150]}...')\n",
    "\n",
    "print(f\"üîé Results for '{query2}':\", results2)\n",
    "for i in results2:\n",
    "    print(f'‚Üí Doc {i} preview: {documents[i][:150]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30aa819",
   "metadata": {},
   "source": [
    "## üß™ Six Core NLP Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e344ad11",
   "metadata": {},
   "source": [
    "### üîπ Term-Document Incidence Matrix\n",
    "\n",
    "The **Term-Document Incidence Matrix** is a binary matrix that shows whether a term $t$ appears in a document $d$.\n",
    "\n",
    "- Rows represent terms in the vocabulary  \n",
    "- Columns represent documents in the corpus  \n",
    "- Each entry $w_{t,d}$ is defined as:\n",
    "\n",
    "$$\n",
    "w_{t,d} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } t \\in d \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is a **binary representation** ‚Äî it only records the **presence or absence** of a term, not how many times it appears.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7655b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Term-Document Incidence Matrix (Filtered for Phrases):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "crime and punishment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "this ebook",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "546901ed-a826-4729-83d2-3d1c5a2669a1",
       "rows": [
        [
         "Doc1",
         "0",
         "1"
        ],
        [
         "Doc2",
         "0",
         "1"
        ],
        [
         "Doc3",
         "0",
         "1"
        ],
        [
         "Doc4",
         "1",
         "1"
        ],
        [
         "Doc5",
         "0",
         "1"
        ],
        [
         "Doc6",
         "0",
         "1"
        ],
        [
         "Doc7",
         "0",
         "1"
        ],
        [
         "Doc8",
         "0",
         "1"
        ],
        [
         "Doc9",
         "0",
         "1"
        ],
        [
         "Doc10",
         "0",
         "1"
        ],
        [
         "Doc11",
         "0",
         "1"
        ],
        [
         "Doc12",
         "0",
         "1"
        ],
        [
         "Doc13",
         "0",
         "1"
        ],
        [
         "Doc14",
         "0",
         "1"
        ],
        [
         "Doc15",
         "0",
         "1"
        ],
        [
         "Doc16",
         "0",
         "1"
        ],
        [
         "Doc17",
         "0",
         "1"
        ],
        [
         "Doc18",
         "0",
         "1"
        ],
        [
         "Doc19",
         "0",
         "1"
        ],
        [
         "Doc20",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime and punishment</th>\n",
       "      <th>this ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crime and punishment  this ebook\n",
       "Doc1                      0           1\n",
       "Doc2                      0           1\n",
       "Doc3                      0           1\n",
       "Doc4                      1           1\n",
       "Doc5                      0           1\n",
       "Doc6                      0           1\n",
       "Doc7                      0           1\n",
       "Doc8                      0           1\n",
       "Doc9                      0           1\n",
       "Doc10                     0           1\n",
       "Doc11                     0           1\n",
       "Doc12                     0           1\n",
       "Doc13                     0           1\n",
       "Doc14                     0           1\n",
       "Doc15                     0           1\n",
       "Doc16                     0           1\n",
       "Doc17                     0           1\n",
       "Doc18                     0           1\n",
       "Doc19                     0           1\n",
       "Doc20                     0           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    " \n",
    "#  Load text documents using  function\n",
    "documents = load_documents('sample_docs/')\n",
    "doc_ids = [f\"Doc{i+1}\" for i in range(len(documents))]\n",
    " \n",
    "#  Create CountVectorizer to capture unigrams to trigrams\n",
    "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\n",
    " \n",
    "#  Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    " \n",
    "#  Create Term-Document Incidence Matrix\n",
    "incidence_matrix = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    index=doc_ids,\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    " \n",
    "#  Filter for specific phrases\n",
    "target_phrases = [\"crime and punishment\", \"this ebook\"]\n",
    "filtered_columns = [phrase for phrase in target_phrases if phrase in incidence_matrix.columns]\n",
    "filtered_matrix = incidence_matrix[filtered_columns]\n",
    " \n",
    "#  Display\n",
    "print(\" Term-Document Incidence Matrix (Filtered for Phrases):\")\n",
    "display(filtered_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea540da",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point Term-Document Incidence Matrix\n",
    ">  To check if a phrase like \"crime and punishment\" or \"this ebook\" appears in a document, we split the phrase into words and check if both words have a 1 in the same document column. If they do, the document contains both words. But this matrix doesn‚Äôt check if the words are next to each other,  just that they are present.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f0344",
   "metadata": {},
   "source": [
    "### üîπ Term Frequency (TF)\n",
    "\n",
    "**Term Frequency (TF)** measures how frequently a term $t$ appears in a document $d$.\n",
    "\n",
    "$$\n",
    "tf_{t,d} = f_{t,d}\n",
    "$$\n",
    "\n",
    "Where $f_{t,d}$ is the raw count of term $t$ in document $d$.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- TF reflects the importance of a word **within a specific document**.\n",
    "- A higher TF means the term is likely central to the topic of that document.\n",
    "- It's used as the **first step** in vectorizing text for machine learning models like classification, clustering, or information retrieval.\n",
    "\n",
    "TF is most effective when combined with **IDF** (Inverse Document Frequency) to balance against very common terms across the corpus.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b96e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Document: Doc5\n",
      "\n",
      " Raw Term Frequencies:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Raw TF",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8b07569b-0795-4696-b48c-825b3a04406a",
       "rows": [
        [
         "0",
         "Ôªøthe",
         "1"
        ],
        [
         "1",
         "project",
         "83"
        ],
        [
         "2",
         "gutenberg",
         "25"
        ],
        [
         "3",
         "ebook",
         "8"
        ],
        [
         "4",
         "of",
         "144"
        ],
        [
         "5",
         "the",
         "267"
        ],
        [
         "6",
         "eyes",
         "11"
        ],
        [
         "7",
         "have",
         "14"
        ],
        [
         "8",
         "it",
         "32"
        ],
        [
         "9",
         "this",
         "58"
        ],
        [
         "10",
         "is",
         "24"
        ],
        [
         "11",
         "for",
         "32"
        ],
        [
         "12",
         "use",
         "12"
        ],
        [
         "13",
         "anyone",
         "4"
        ],
        [
         "14",
         "anywhere",
         "2"
        ],
        [
         "15",
         "in",
         "86"
        ],
        [
         "16",
         "united",
         "15"
        ],
        [
         "17",
         "states",
         "11"
        ],
        [
         "18",
         "and",
         "87"
        ],
        [
         "19",
         "most",
         "6"
        ],
        [
         "20",
         "other",
         "17"
        ],
        [
         "21",
         "parts",
         "2"
        ],
        [
         "22",
         "world",
         "2"
        ],
        [
         "23",
         "at",
         "21"
        ],
        [
         "24",
         "no",
         "19"
        ],
        [
         "25",
         "cost",
         "2"
        ],
        [
         "26",
         "with",
         "53"
        ],
        [
         "27",
         "almost",
         "2"
        ],
        [
         "28",
         "restrictions",
         "2"
        ],
        [
         "29",
         "whatsoever.",
         "2"
        ],
        [
         "30",
         "you",
         "75"
        ],
        [
         "31",
         "may",
         "15"
        ],
        [
         "32",
         "copy",
         "8"
        ],
        [
         "33",
         "it,",
         "3"
        ],
        [
         "34",
         "give",
         "4"
        ],
        [
         "35",
         "away",
         "2"
        ],
        [
         "36",
         "or",
         "74"
        ],
        [
         "37",
         "re-use",
         "2"
        ],
        [
         "38",
         "under",
         "7"
        ],
        [
         "39",
         "terms",
         "22"
        ],
        [
         "40",
         "license",
         "12"
        ],
        [
         "41",
         "included",
         "2"
        ],
        [
         "42",
         "online",
         "6"
        ],
        [
         "43",
         "www.gutenberg.org.",
         "4"
        ],
        [
         "44",
         "if",
         "23"
        ],
        [
         "45",
         "are",
         "23"
        ],
        [
         "46",
         "not",
         "35"
        ],
        [
         "47",
         "located",
         "7"
        ],
        [
         "48",
         "states,",
         "4"
        ],
        [
         "49",
         "will",
         "8"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1328
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Raw TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ôªøthe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebook</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>produce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ebooks,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>newsletter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>ebooks.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term  Raw TF\n",
       "0           Ôªøthe       1\n",
       "1        project      83\n",
       "2      gutenberg      25\n",
       "3          ebook       8\n",
       "4             of     144\n",
       "...          ...     ...\n",
       "1323     produce       1\n",
       "1324     ebooks,       1\n",
       "1325   subscribe       1\n",
       "1326  newsletter       1\n",
       "1327     ebooks.       1\n",
       "\n",
       "[1328 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìè Normalized Term Frequencies:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TF (Normalized)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "237faa58-2cbf-4081-946c-ba7c9c9e19eb",
       "rows": [
        [
         "0",
         "Ôªøthe",
         "0.00023702299123014932"
        ],
        [
         "1",
         "project",
         "0.019672908272102396"
        ],
        [
         "2",
         "gutenberg",
         "0.005925574780753733"
        ],
        [
         "3",
         "ebook",
         "0.0018961839298411946"
        ],
        [
         "4",
         "of",
         "0.034131310737141506"
        ],
        [
         "5",
         "the",
         "0.06328513865844987"
        ],
        [
         "6",
         "eyes",
         "0.0026072529035316427"
        ],
        [
         "7",
         "have",
         "0.0033183218772220905"
        ],
        [
         "8",
         "it",
         "0.007584735719364778"
        ],
        [
         "9",
         "this",
         "0.01374733349134866"
        ],
        [
         "10",
         "is",
         "0.005688551789523584"
        ],
        [
         "11",
         "for",
         "0.007584735719364778"
        ],
        [
         "12",
         "use",
         "0.002844275894761792"
        ],
        [
         "13",
         "anyone",
         "0.0009480919649205973"
        ],
        [
         "14",
         "anywhere",
         "0.00047404598246029864"
        ],
        [
         "15",
         "in",
         "0.020383977245792842"
        ],
        [
         "16",
         "united",
         "0.00355534486845224"
        ],
        [
         "17",
         "states",
         "0.0026072529035316427"
        ],
        [
         "18",
         "and",
         "0.020621000237022992"
        ],
        [
         "19",
         "most",
         "0.001422137947380896"
        ],
        [
         "20",
         "other",
         "0.004029390850912538"
        ],
        [
         "21",
         "parts",
         "0.00047404598246029864"
        ],
        [
         "22",
         "world",
         "0.00047404598246029864"
        ],
        [
         "23",
         "at",
         "0.0049774828158331355"
        ],
        [
         "24",
         "no",
         "0.004503436833372837"
        ],
        [
         "25",
         "cost",
         "0.00047404598246029864"
        ],
        [
         "26",
         "with",
         "0.012562218535197914"
        ],
        [
         "27",
         "almost",
         "0.00047404598246029864"
        ],
        [
         "28",
         "restrictions",
         "0.00047404598246029864"
        ],
        [
         "29",
         "whatsoever.",
         "0.00047404598246029864"
        ],
        [
         "30",
         "you",
         "0.0177767243422612"
        ],
        [
         "31",
         "may",
         "0.00355534486845224"
        ],
        [
         "32",
         "copy",
         "0.0018961839298411946"
        ],
        [
         "33",
         "it,",
         "0.000711068973690448"
        ],
        [
         "34",
         "give",
         "0.0009480919649205973"
        ],
        [
         "35",
         "away",
         "0.00047404598246029864"
        ],
        [
         "36",
         "or",
         "0.01753970135103105"
        ],
        [
         "37",
         "re-use",
         "0.00047404598246029864"
        ],
        [
         "38",
         "under",
         "0.0016591609386110452"
        ],
        [
         "39",
         "terms",
         "0.0052145058070632855"
        ],
        [
         "40",
         "license",
         "0.002844275894761792"
        ],
        [
         "41",
         "included",
         "0.00047404598246029864"
        ],
        [
         "42",
         "online",
         "0.001422137947380896"
        ],
        [
         "43",
         "www.gutenberg.org.",
         "0.0009480919649205973"
        ],
        [
         "44",
         "if",
         "0.005451528798293435"
        ],
        [
         "45",
         "are",
         "0.005451528798293435"
        ],
        [
         "46",
         "not",
         "0.008295804693055226"
        ],
        [
         "47",
         "located",
         "0.0016591609386110452"
        ],
        [
         "48",
         "states,",
         "0.0009480919649205973"
        ],
        [
         "49",
         "will",
         "0.0018961839298411946"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1328
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>TF (Normalized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ôªøthe</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>0.019673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>0.005926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebook</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>0.034131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>produce</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>ebooks,</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>newsletter</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>ebooks.</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term  TF (Normalized)\n",
       "0           Ôªøthe         0.000237\n",
       "1        project         0.019673\n",
       "2      gutenberg         0.005926\n",
       "3          ebook         0.001896\n",
       "4             of         0.034131\n",
       "...          ...              ...\n",
       "1323     produce         0.000237\n",
       "1324     ebooks,         0.000237\n",
       "1325   subscribe         0.000237\n",
       "1326  newsletter         0.000237\n",
       "1327     ebooks.         0.000237\n",
       "\n",
       "[1328 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    " \n",
    "# Load all documents\n",
    "documents = load_documents('sample_docs/')\n",
    "doc_ids = [f\"Doc{i+1}\" for i in range(len(documents))]\n",
    " \n",
    "doc_index = 4 \n",
    "doc_text = documents[doc_index].lower().split()  # Simple tokenizer\n",
    " \n",
    "# Raw Term Frequency\n",
    "tf_raw = Counter(doc_text)\n",
    "total_terms = len(doc_text)\n",
    " \n",
    "# Normalized Term Frequency\n",
    "tf_normalized = {term: count / total_terms for term, count in tf_raw.items()}\n",
    " \n",
    "# Display\n",
    "print(f\" Document: {doc_ids[doc_index]}\")\n",
    "print(\"\\n Raw Term Frequencies:\")\n",
    "display(pd.DataFrame(tf_raw.items(), columns=[\"Term\", \"Raw TF\"]))\n",
    " \n",
    "print(\"\\nüìè Normalized Term Frequencies:\")\n",
    "display(pd.DataFrame(tf_normalized.items(), columns=[\"Term\", \"TF (Normalized)\"]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c78e4b",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point TF:\n",
    ">  Looking at the normalized TF for a document, terms with higher TF values are more important because they appear more frequently relative to the document length. Comparing Doc1 with another document, words like ‚Äúcrime,‚Äù ‚Äúpunishment,‚Äù or ‚Äúebook‚Äù with higher normalized TFs suggest the document‚Äôs main themes. This helps an AI agent prioritize these terms when building context or answering queries related to those topics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808aeaa2",
   "metadata": {},
   "source": [
    "### üîπ Log Frequency Weight\n",
    "\n",
    "To reduce the impact of very frequent terms, **log frequency weighting** is applied.\n",
    "\n",
    "$$\n",
    "w_{t,d} =\n",
    "\\begin{cases}\n",
    "1 + \\log_{10}(f_{t,d}) & \\text{if } f_{t,d} > 0 \\\\\n",
    "0 & \\text{if } f_{t,d} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This transformation reduces the skew caused by terms that appear many times in a document. Instead of allowing their raw frequency to dominate, we scale their contribution **logarithmically**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- Frequent terms are not always the most **important** terms.\n",
    "- Log scaling ensures that:\n",
    "  - Words with a raw count of 1 are preserved ($1 + \\\\log_{10}(1) = 1$),\n",
    "  - But words with very high counts (e.g., 1000) don‚Äôt dominate the document vector.\n",
    "\n",
    "This helps **normalize the influence** of repetitive terms and improve the **numerical stability** of document representations in models.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7943cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Document: Doc12\n",
      " Log Frequency Weighting:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Raw TF (f_{t,d})",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Log Weight (w_{t,d})",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4a4ab29e-520f-467c-a6ae-711dbf8dba59",
       "rows": [
        [
         "0",
         "Ôªøthe",
         "1",
         "1.0"
        ],
        [
         "1",
         "project",
         "83",
         "2.9190780923760737"
        ],
        [
         "2",
         "gutenberg",
         "25",
         "2.3979400086720375"
        ],
        [
         "3",
         "ebook",
         "8",
         "1.9030899869919435"
        ],
        [
         "4",
         "of",
         "122",
         "3.0863598306747484"
        ],
        [
         "5",
         "√©crits",
         "10",
         "2.0"
        ],
        [
         "6",
         "spirituels",
         "9",
         "1.9542425094393248"
        ],
        [
         "7",
         "de",
         "2835",
         "4.452553063228925"
        ],
        [
         "8",
         "charles",
         "35",
         "2.5440680443502757"
        ],
        [
         "9",
         "foucauld",
         "27",
         "2.4313637641589874"
        ],
        [
         "10",
         "this",
         "45",
         "2.653212513775344"
        ],
        [
         "11",
         "is",
         "22",
         "2.342422680822206"
        ],
        [
         "12",
         "for",
         "26",
         "2.414973347970818"
        ],
        [
         "13",
         "the",
         "187",
         "3.271841606536499"
        ],
        [
         "14",
         "use",
         "12",
         "2.079181246047625"
        ],
        [
         "15",
         "anyone",
         "4",
         "1.6020599913279625"
        ],
        [
         "16",
         "anywhere",
         "2",
         "1.3010299956639813"
        ],
        [
         "17",
         "in",
         "68",
         "2.8325089127062366"
        ],
        [
         "18",
         "united",
         "15",
         "2.1760912590556813"
        ],
        [
         "19",
         "states",
         "11",
         "2.0413926851582254"
        ],
        [
         "20",
         "and",
         "66",
         "2.8195439355418688"
        ],
        [
         "21",
         "most",
         "5",
         "1.6989700043360187"
        ],
        [
         "22",
         "other",
         "17",
         "2.230448921378274"
        ],
        [
         "23",
         "parts",
         "2",
         "1.3010299956639813"
        ],
        [
         "24",
         "world",
         "2",
         "1.3010299956639813"
        ],
        [
         "25",
         "at",
         "14",
         "2.146128035678238"
        ],
        [
         "26",
         "no",
         "10",
         "2.0"
        ],
        [
         "27",
         "cost",
         "2",
         "1.3010299956639813"
        ],
        [
         "28",
         "with",
         "47",
         "2.6720978579357175"
        ],
        [
         "29",
         "almost",
         "2",
         "1.3010299956639813"
        ],
        [
         "30",
         "restrictions",
         "2",
         "1.3010299956639813"
        ],
        [
         "31",
         "whatsoever.",
         "2",
         "1.3010299956639813"
        ],
        [
         "32",
         "you",
         "73",
         "2.863322860120456"
        ],
        [
         "33",
         "may",
         "15",
         "2.1760912590556813"
        ],
        [
         "34",
         "copy",
         "8",
         "1.9030899869919435"
        ],
        [
         "35",
         "it,",
         "3",
         "1.4771212547196624"
        ],
        [
         "36",
         "give",
         "4",
         "1.6020599913279625"
        ],
        [
         "37",
         "it",
         "12",
         "2.079181246047625"
        ],
        [
         "38",
         "away",
         "2",
         "1.3010299956639813"
        ],
        [
         "39",
         "or",
         "74",
         "2.8692317197309762"
        ],
        [
         "40",
         "re-use",
         "2",
         "1.3010299956639813"
        ],
        [
         "41",
         "under",
         "6",
         "1.7781512503836436"
        ],
        [
         "42",
         "terms",
         "22",
         "2.342422680822206"
        ],
        [
         "43",
         "license",
         "12",
         "2.079181246047625"
        ],
        [
         "44",
         "included",
         "2",
         "1.3010299956639813"
        ],
        [
         "45",
         "online",
         "5",
         "1.6989700043360187"
        ],
        [
         "46",
         "www.gutenberg.org.",
         "4",
         "1.6020599913279625"
        ],
        [
         "47",
         "if",
         "21",
         "2.3222192947339195"
        ],
        [
         "48",
         "are",
         "23",
         "2.361727836017593"
        ],
        [
         "49",
         "not",
         "28",
         "2.4471580313422194"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 11710
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Raw TF (f_{t,d})</th>\n",
       "      <th>Log Weight (w_{t,d})</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ôªøthe</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>83</td>\n",
       "      <td>2.919078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gutenberg</td>\n",
       "      <td>25</td>\n",
       "      <td>2.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebook</td>\n",
       "      <td>8</td>\n",
       "      <td>1.903090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>122</td>\n",
       "      <td>3.086360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11705</th>\n",
       "      <td>ebooks,</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11706</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11707</th>\n",
       "      <td>newsletter</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>hear</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11709</th>\n",
       "      <td>ebooks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11710 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term  Raw TF (f_{t,d})  Log Weight (w_{t,d})\n",
       "0            Ôªøthe                 1              1.000000\n",
       "1         project                83              2.919078\n",
       "2       gutenberg                25              2.397940\n",
       "3           ebook                 8              1.903090\n",
       "4              of               122              3.086360\n",
       "...           ...               ...                   ...\n",
       "11705     ebooks,                 1              1.000000\n",
       "11706   subscribe                 1              1.000000\n",
       "11707  newsletter                 1              1.000000\n",
       "11708        hear                 1              1.000000\n",
       "11709     ebooks.                 1              1.000000\n",
       "\n",
       "[11710 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    " \n",
    "# Load documents\n",
    "documents = load_documents('sample_docs/')\n",
    "doc_ids = [f\"Doc{i+1}\" for i in range(len(documents))]\n",
    " \n",
    "# Choose which document to process\n",
    "doc_index = 11 # Change index from 0‚Äì19 to process a different document\n",
    "tokens = documents[doc_index].lower().split()\n",
    " \n",
    "# Raw term frequency\n",
    "raw_tf = Counter(tokens)\n",
    " \n",
    "# Log frequency weighting\n",
    "log_weighted_tf = {\n",
    "    term: 1 + np.log10(freq) if freq > 0 else 0\n",
    "    for term, freq in raw_tf.items()\n",
    "}\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Term\": list(raw_tf.keys()),\n",
    "    \"Raw TF (f_{t,d})\": list(raw_tf.values()),\n",
    "    \"Log Weight (w_{t,d})\": list(log_weighted_tf.values())\n",
    "})\n",
    " \n",
    "print(f\" Document: {doc_ids[doc_index]}\")\n",
    "print(\" Log Frequency Weighting:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa7629",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point Log Frequency:\n",
    ">  Based on the log frequency weighting output for Doc12, terms with higher raw frequencies and consequently higher log weights‚Äîsuch as ‚Äúproject,‚Äù ‚Äúgutenberg,‚Äù and ‚Äúof‚Äù‚Äîare likely the most important because they appear frequently and thus carry more significance within the document. Comparing these with another document‚Äôs TF or log weights can highlight thematic differences. For example, if ‚Äúebook‚Äù has a higher weight in Doc12 but is less frequent in Doc1, it suggests Doc12 focuses more on ebooks, helping an AI agent prioritize relevant documents when answering queries or building context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990742cf",
   "metadata": {},
   "source": [
    "### üîπ Document Frequency (DF)\n",
    "\n",
    "**Document Frequency** is the number of documents in which a term $t$ appears:\n",
    "\n",
    "$$\n",
    "df_t = |\\{ d \\in D : t \\in d \\}|\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $df_t$ is the document frequency of term $t$\n",
    "- $D$ is the set of all documents in the corpus\n",
    "- $t \\in d$ means the term $t$ appears in document $d$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- It helps you understand **how common or rare** a word is across the entire document set.\n",
    "- Words with **high DF** (e.g., ‚Äúthe‚Äù, ‚Äúand‚Äù) occur in many documents and are often **less informative**.\n",
    "- Words with **low DF** are more likely to be **specific and meaningful** for distinguishing between documents.\n",
    "- DF is a key ingredient in calculating **Inverse Document Frequency (IDF)**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59a51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Document Frequency (DF) Table:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Document Frequency (df_t)",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c00c7e3a-329d-4e95-8fb6-35264d9f10b1",
       "rows": [
        [
         "14835",
         "apply",
         "20"
        ],
        [
         "101051",
         "your",
         "20"
        ],
        [
         "79009",
         "redistribute",
         "20"
        ],
        [
         "79010",
         "redistributing",
         "20"
        ],
        [
         "79011",
         "redistribution",
         "20"
        ],
        [
         "79100",
         "references",
         "20"
        ],
        [
         "14888",
         "approach",
         "20"
        ],
        [
         "100874",
         "years",
         "20"
        ],
        [
         "59388",
         "lot",
         "20"
        ],
        [
         "79221",
         "refund",
         "20"
        ],
        [
         "59251",
         "long",
         "20"
        ],
        [
         "59312",
         "loose",
         "20"
        ],
        [
         "79333",
         "registered",
         "20"
        ],
        [
         "59092",
         "located",
         "20"
        ],
        [
         "59095",
         "locations",
         "20"
        ],
        [
         "79385",
         "regulating",
         "20"
        ],
        [
         "58644",
         "literary",
         "20"
        ],
        [
         "58534",
         "linked",
         "20"
        ],
        [
         "58536",
         "links",
         "20"
        ],
        [
         "71552",
         "person",
         "20"
        ],
        [
         "71921",
         "pg",
         "20"
        ],
        [
         "71923",
         "pglaf",
         "20"
        ],
        [
         "58444",
         "limitation",
         "20"
        ],
        [
         "58447",
         "limited",
         "20"
        ],
        [
         "79636",
         "remain",
         "20"
        ],
        [
         "79639",
         "remaining",
         "20"
        ],
        [
         "79545",
         "release",
         "20"
        ],
        [
         "79687",
         "remedies",
         "20"
        ],
        [
         "60027",
         "machine",
         "20"
        ],
        [
         "60294",
         "mail",
         "20"
        ],
        [
         "79791",
         "remove",
         "20"
        ],
        [
         "58211",
         "library",
         "20"
        ],
        [
         "58257",
         "license",
         "20"
        ],
        [
         "58258",
         "licensed",
         "20"
        ],
        [
         "58318",
         "lieu",
         "20"
        ],
        [
         "58324",
         "life",
         "20"
        ],
        [
         "79792",
         "removed",
         "20"
        ],
        [
         "79829",
         "renamed",
         "20"
        ],
        [
         "15355",
         "are",
         "20"
        ],
        [
         "58117",
         "liability",
         "20"
        ],
        [
         "58118",
         "liable",
         "20"
        ],
        [
         "57695",
         "legal",
         "20"
        ],
        [
         "57698",
         "legally",
         "20"
        ],
        [
         "80067",
         "replace",
         "20"
        ],
        [
         "80069",
         "replacement",
         "20"
        ],
        [
         "80094",
         "reported",
         "20"
        ],
        [
         "80100",
         "reports",
         "20"
        ],
        [
         "80198",
         "representations",
         "20"
        ],
        [
         "57573",
         "learn",
         "20"
        ],
        [
         "60301",
         "main",
         "20"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 101910
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Document Frequency (df_t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>apply</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101051</th>\n",
       "      <td>your</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79009</th>\n",
       "      <td>redistribute</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79010</th>\n",
       "      <td>redistributing</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79011</th>\n",
       "      <td>redistribution</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101910 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Term  Document Frequency (df_t)\n",
       "14835            apply                         20\n",
       "101051            your                         20\n",
       "79009     redistribute                         20\n",
       "79010   redistributing                         20\n",
       "79011   redistribution                         20\n",
       "...                ...                        ...\n",
       "15                 034                          1\n",
       "14                 033                          1\n",
       "13                 030                          1\n",
       "12                 024                          1\n",
       "0                   00                          1\n",
       "\n",
       "[101910 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Load documents\n",
    "documents = load_documents('sample_docs/')\n",
    "doc_ids = [f\"Doc{i+1}\" for i in range(len(documents))]\n",
    " \n",
    "# Create CountVectorizer for raw counts\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    " \n",
    "# Extract terms and term-document matrix\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    " \n",
    "# Compute Document Frequency (number of docs where term appears)\n",
    "df_counts = (X_array > 0).sum(axis=0)\n",
    " \n",
    "# Build DataFrame\n",
    "df_table = pd.DataFrame({\n",
    "    \"Term\": terms,\n",
    "    \"Document Frequency (df_t)\": df_counts\n",
    "}).sort_values(\"Document Frequency (df_t)\", ascending=False)\n",
    " \n",
    "print(\" Document Frequency (DF) Table:\")\n",
    "display(df_table)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c94cd3",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point Document Frequency:\n",
    "> Choosing a term like ‚Äúredistribute‚Äù which appears in all 20 documents (high document frequency), its impact on TF-IDF weighting would be lower because it‚Äôs very common and less helpful for distinguishing between documents. In contrast, a term like ‚Äúfun‚Äù that appears in only one document (low document frequency) would get a higher TF-IDF weight, making it more important for identifying unique or specific content. This helps an AI agent focus on terms that better differentiate documents when building context or answering queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08628b",
   "metadata": {},
   "source": [
    "### üîπ Inverse Document Frequency (IDF)\n",
    "\n",
    "**Inverse Document Frequency (IDF)** measures how rare or informative a term is across the entire corpus:\n",
    "\n",
    "$$\n",
    "idf_t = \\log_{10} \\left( \\frac{N}{df_t} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of documents in the corpus  \n",
    "- $df_t$ is the number of documents that contain the term $t$\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- IDF is used to **downweight common terms** and **upweight rare ones**.\n",
    "- Words like ‚Äúthe‚Äù, ‚Äúand‚Äù, or ‚Äúdata‚Äù appear frequently and are less helpful in distinguishing documents.\n",
    "- Terms that appear in **fewer documents** are often **more informative** and **discriminative**.\n",
    "- IDF is a core component of **TF-IDF**, a widely used technique in search engines, document classification, and clustering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f404dd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Inverse Document Frequency (IDF) Table:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Term",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Document Frequency (df_t)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IDF (log10(N / df_t))",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "999780de-9369-4a68-8bef-1b955c36e07c",
       "rows": [
        [
         "101909",
         "‚ÇÅ‚ÇÇ",
         "1",
         "1.3010299956639813"
        ],
        [
         "0",
         "00",
         "1",
         "1.3010299956639813"
        ],
        [
         "101908",
         "·ø•ŒøŒπŒ∂Œ∑Œ¥·Ω∏ŒΩ",
         "1",
         "1.3010299956639813"
        ],
        [
         "2",
         "001",
         "1",
         "1.3010299956639813"
        ],
        [
         "3",
         "004",
         "1",
         "1.3010299956639813"
        ],
        [
         "101892",
         "·º†ŒªŒπŒ≤Œ¨œÑŒøœÖ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101891",
         "·ºîœÅœáŒµŒ∏",
         "1",
         "1.3010299956639813"
        ],
        [
         "101890",
         "·ºîŒ¥œÅŒ±Œ∫Œµ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101889",
         "·ºîŒ≥œâ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101888",
         "·ºëœÑŒ±ŒπœÅŒπŒ∫ŒøŒπ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101887",
         "·ºêœáŒ∏·Ω≤œÇ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101886",
         "·ºêœÄŒπœÉœÑŒÆŒºŒ∑",
         "1",
         "1.3010299956639813"
        ],
        [
         "101885",
         "·ºêœÄ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101884",
         "·ºêŒΩŒ≠œÅŒ≥ŒµŒπŒ±",
         "1",
         "1.3010299956639813"
        ],
        [
         "101883",
         "·ºêŒΩ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101882",
         "·ºÖœÑŒµ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101881",
         "·ºÑœÜœÅœâŒΩ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101880",
         "·ºÄœÄœåŒΩŒ±ŒΩœÑŒø",
         "1",
         "1.3010299956639813"
        ],
        [
         "101879",
         "·ºÄœÄ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101878",
         "·ºÄŒΩŒ±ŒπœÅŒµŒ∏Œ≠ŒΩœÑŒµœÇ",
         "1",
         "1.3010299956639813"
        ],
        [
         "101877",
         "·ºÄŒΩŒ¨ŒºŒΩŒ∑œÉŒπœÇ",
         "1",
         "1.3010299956639813"
        ],
        [
         "35",
         "079",
         "1",
         "1.3010299956639813"
        ],
        [
         "34",
         "078",
         "1",
         "1.3010299956639813"
        ],
        [
         "33",
         "077",
         "1",
         "1.3010299956639813"
        ],
        [
         "32",
         "076",
         "1",
         "1.3010299956639813"
        ],
        [
         "31",
         "074",
         "1",
         "1.3010299956639813"
        ],
        [
         "30",
         "065",
         "1",
         "1.3010299956639813"
        ],
        [
         "29",
         "061",
         "1",
         "1.3010299956639813"
        ],
        [
         "28",
         "059",
         "1",
         "1.3010299956639813"
        ],
        [
         "27",
         "058",
         "1",
         "1.3010299956639813"
        ],
        [
         "26",
         "056",
         "1",
         "1.3010299956639813"
        ],
        [
         "25",
         "053",
         "1",
         "1.3010299956639813"
        ],
        [
         "24",
         "051",
         "1",
         "1.3010299956639813"
        ],
        [
         "23",
         "050",
         "1",
         "1.3010299956639813"
        ],
        [
         "22",
         "048",
         "1",
         "1.3010299956639813"
        ],
        [
         "21",
         "047",
         "1",
         "1.3010299956639813"
        ],
        [
         "52",
         "100th",
         "1",
         "1.3010299956639813"
        ],
        [
         "48",
         "097",
         "1",
         "1.3010299956639813"
        ],
        [
         "46",
         "095",
         "1",
         "1.3010299956639813"
        ],
        [
         "45",
         "094",
         "1",
         "1.3010299956639813"
        ],
        [
         "44",
         "093",
         "1",
         "1.3010299956639813"
        ],
        [
         "43",
         "092",
         "1",
         "1.3010299956639813"
        ],
        [
         "42",
         "090",
         "1",
         "1.3010299956639813"
        ],
        [
         "41",
         "089",
         "1",
         "1.3010299956639813"
        ],
        [
         "40",
         "087",
         "1",
         "1.3010299956639813"
        ],
        [
         "39",
         "086",
         "1",
         "1.3010299956639813"
        ],
        [
         "38",
         "085",
         "1",
         "1.3010299956639813"
        ],
        [
         "37",
         "084",
         "1",
         "1.3010299956639813"
        ],
        [
         "66",
         "1091",
         "1",
         "1.3010299956639813"
        ],
        [
         "61",
         "10554",
         "1",
         "1.3010299956639813"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 101910
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Document Frequency (df_t)</th>\n",
       "      <th>IDF (log10(N / df_t))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101909</th>\n",
       "      <td>‚ÇÅ‚ÇÇ</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101908</th>\n",
       "      <td>·ø•ŒøŒπŒ∂Œ∑Œ¥·Ω∏ŒΩ</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72642</th>\n",
       "      <td>place</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14781</th>\n",
       "      <td>appears</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14780</th>\n",
       "      <td>appearing</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14888</th>\n",
       "      <td>approach</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>apply</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101910 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term  Document Frequency (df_t)  IDF (log10(N / df_t))\n",
       "101909         ‚ÇÅ‚ÇÇ                          1                1.30103\n",
       "0              00                          1                1.30103\n",
       "101908   ·ø•ŒøŒπŒ∂Œ∑Œ¥·Ω∏ŒΩ                          1                1.30103\n",
       "2             001                          1                1.30103\n",
       "3             004                          1                1.30103\n",
       "...           ...                        ...                    ...\n",
       "72642       place                         20                0.00000\n",
       "14781     appears                         20                0.00000\n",
       "14780   appearing                         20                0.00000\n",
       "14888    approach                         20                0.00000\n",
       "14835       apply                         20                0.00000\n",
       "\n",
       "[101910 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Load documents\n",
    "documents = load_documents('sample_docs/')\n",
    "N = len(documents)  # Total number of documents\n",
    " \n",
    "# Create CountVectorizer and get document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    " \n",
    "# Document frequency for each term\n",
    "df_counts = (X_array > 0).sum(axis=0)\n",
    " \n",
    "# Compute IDF: log10(N / df_t)\n",
    "idf_values = np.log10(N / df_counts)\n",
    " \n",
    "# Create DataFrame\n",
    "idf_table = pd.DataFrame({\n",
    "    \"Term\": terms,\n",
    "    \"Document Frequency (df_t)\": df_counts,\n",
    "    \"IDF (log10(N / df_t))\": idf_values\n",
    "}).sort_values(\"IDF (log10(N / df_t))\", ascending=False)\n",
    " \n",
    "print(\" Inverse Document Frequency (IDF) Table:\")\n",
    "display(idf_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05571e5e",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point IDF:\n",
    "> In this step, we calculated the Inverse Document Frequency (IDF) for each term in the corpus. The IDF metric helps us identify rare or unique terms that appear in fewer documents ‚Äî giving them more importance during TF-IDF computation. As shown in the table, many terms like '00', '001', and others have an IDF value of approximately 1.30, which suggests they appear in only one document out of the entire set. However, we also noticed some noisy or non-English tokens like ·ø•ŒøŒπŒ∂Œ∑Œ¥·Ω∏ŒΩ or purely numeric tokens, which indicates a need for better token filtering or preprocessing to ensure cleaner term relevance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5718af58",
   "metadata": {},
   "source": [
    "### üîπ TF-IDF Weighting\n",
    "\n",
    "**TF-IDF (Term Frequency‚ÄìInverse Document Frequency)** scores each term $t$ in document $d$ based on how frequent and how rare it is:\n",
    "\n",
    "$$\n",
    "w_{t,d} = \\left(1 + \\log_{10}(f_{t,d})\\right) \\times \\log_{10} \\left( \\frac{N}{df_t} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $f_{t,d}$ is the raw count of term $t$ in document $d$\n",
    "- $df_t$ is the number of documents that contain term $t$\n",
    "- $N$ is the total number of documents in the corpus\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Use It?\n",
    "\n",
    "- TF-IDF balances **term importance within a document** (TF) against **term commonality across all documents** (IDF).\n",
    "- It **boosts rare, relevant words** while **suppressing frequent, generic words**.\n",
    "- TF-IDF is foundational in:\n",
    "  - Information Retrieval (search engines)\n",
    "  - Document similarity\n",
    "  - Feature engineering for classification or clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f380acb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_18428\\911187246.py:24: RuntimeWarning: divide by zero encountered in log10\n",
      "  tf_log = 1 + np.where(X_array > 0, np.log10(X_array), 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Manual TF-IDF Matrix for Selected Phrases:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "crime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "and",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "punishment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "this",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ebook",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bffd713f-e75f-431e-8637-e7fe47d46996",
       "rows": [
        [
         "Doc1",
         "0.445",
         "0.0",
         "0.318",
         "0.0",
         "0.0"
        ],
        [
         "Doc2",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc3",
         "0.301",
         "0.0",
         "0.276",
         "0.0",
         "0.0"
        ],
        [
         "Doc4",
         "0.825",
         "0.0",
         "0.356",
         "0.0",
         "0.0"
        ],
        [
         "Doc5",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc6",
         "0.301",
         "0.0",
         "0.243",
         "0.0",
         "0.0"
        ],
        [
         "Doc7",
         "0.392",
         "0.0",
         "0.243",
         "0.0",
         "0.0"
        ],
        [
         "Doc8",
         "0.392",
         "0.0",
         "0.276",
         "0.0",
         "0.0"
        ],
        [
         "Doc9",
         "0.392",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc10",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc11",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc12",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc13",
         "0.511",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc14",
         "0.602",
         "0.0",
         "0.507",
         "0.0",
         "0.0"
        ],
        [
         "Doc15",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc16",
         "0.535",
         "0.0",
         "0.276",
         "0.0",
         "0.0"
        ],
        [
         "Doc17",
         "0.636",
         "0.0",
         "0.389",
         "0.0",
         "0.0"
        ],
        [
         "Doc18",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc19",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ],
        [
         "Doc20",
         "0.301",
         "0.0",
         "0.187",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime</th>\n",
       "      <th>and</th>\n",
       "      <th>punishment</th>\n",
       "      <th>this</th>\n",
       "      <th>ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc10</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc11</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc12</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc13</th>\n",
       "      <td>0.511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc14</th>\n",
       "      <td>0.602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc15</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc16</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc17</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc18</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc19</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc20</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crime  and  punishment  this  ebook\n",
       "Doc1   0.445  0.0       0.318   0.0    0.0\n",
       "Doc2   0.301  0.0       0.187   0.0    0.0\n",
       "Doc3   0.301  0.0       0.276   0.0    0.0\n",
       "Doc4   0.825  0.0       0.356   0.0    0.0\n",
       "Doc5   0.301  0.0       0.187   0.0    0.0\n",
       "Doc6   0.301  0.0       0.243   0.0    0.0\n",
       "Doc7   0.392  0.0       0.243   0.0    0.0\n",
       "Doc8   0.392  0.0       0.276   0.0    0.0\n",
       "Doc9   0.392  0.0       0.187   0.0    0.0\n",
       "Doc10  0.301  0.0       0.187   0.0    0.0\n",
       "Doc11  0.301  0.0       0.187   0.0    0.0\n",
       "Doc12  0.301  0.0       0.187   0.0    0.0\n",
       "Doc13  0.511  0.0       0.187   0.0    0.0\n",
       "Doc14  0.602  0.0       0.507   0.0    0.0\n",
       "Doc15  0.301  0.0       0.187   0.0    0.0\n",
       "Doc16  0.535  0.0       0.276   0.0    0.0\n",
       "Doc17  0.636  0.0       0.389   0.0    0.0\n",
       "Doc18  0.301  0.0       0.187   0.0    0.0\n",
       "Doc19  0.301  0.0       0.187   0.0    0.0\n",
       "Doc20  0.301  0.0       0.187   0.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Load documents\n",
    "documents = load_documents('sample_docs/')\n",
    "N = len(documents)\n",
    "doc_ids = [f\"Doc{i+1}\" for i in range(N)]\n",
    " \n",
    "# Key phrases to track\n",
    "target_phrases = [\"crime\",  \"and\", \"punishment\", \"this\", \"ebook\"]\n",
    " \n",
    "# Vectorizer with up to trigrams (to capture phrases)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "X_array = X.toarray()\n",
    " \n",
    "# Document Frequencies and IDF\n",
    "df = (X_array > 0).sum(axis=0)\n",
    "idf = np.log10(N / df)\n",
    " \n",
    "# Log-weighted TF\n",
    "tf_log = 1 + np.where(X_array > 0, np.log10(X_array), 0)\n",
    " \n",
    "# TF-IDF calculation\n",
    "tfidf = tf_log * idf\n",
    " \n",
    "# Full matrix\n",
    "tfidf_df = pd.DataFrame(tfidf, columns=terms, index=doc_ids)\n",
    " \n",
    "# Filter only selected phrases that exist\n",
    "filtered_phrases = [phrase for phrase in target_phrases if phrase in tfidf_df.columns]\n",
    "filtered_tfidf = tfidf_df[filtered_phrases]\n",
    " \n",
    "# Output\n",
    "print(\" Manual TF-IDF Matrix for Selected Phrases:\")\n",
    "display(filtered_tfidf.round(3))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec22502",
   "metadata": {},
   "source": [
    "\n",
    "### üó£ Talking Point TD-IDF:\n",
    "> In this step, we computed the manual TF-IDF weights for selected key terms like 'crime', 'punishment', 'this', and 'ebook' across our document set. As seen in the output, the term 'crime' appears frequently and with higher weight in multiple documents, while 'punishment' and 'ebook' show zero TF-IDF‚Äîindicating that either these terms are absent or not frequent enough to impact weighting. This insight helps us identify which documents are most contextually relevant to specific themes like crime and punishment.\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
